{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvUOuxKqLxYm"
      },
      "source": [
        "# Lab 05: Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVTeENmrLz90"
      },
      "source": [
        "## Multiclass Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rFo9GnOL4Mv"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "Y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58lD1nf4L7IJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgbzfwjtL_Dv"
      },
      "outputs": [],
      "source": [
        "class Data(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.x = torch.from_numpy(X)\n",
        "        self.y = torch.from_numpy(y)\n",
        "        self.len = self.x.shape[0]\n",
        "    def __getitem__(self,index):\n",
        "        return self.x[index], self.y[index]\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt7lT_JxNNp9"
      },
      "outputs": [],
      "source": [
        "train_dataset = Data(x_train, y_train)\n",
        "trainloader = DataLoader(dataset=train_dataset,batch_size=64)\n",
        "val_dataset = Data(x_val, y_val)\n",
        "val_loader = DataLoader(dataset=val_dataset,batch_size=64)\n",
        "test_dataset = Data(x_train, y_train)\n",
        "test_loader = DataLoader(dataset=test_dataset,batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRPGprImNPRG"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self,D_in,H,D_out):\n",
        "        super(Net,self).__init__()\n",
        "        self.linear1=nn.Linear(D_in,H)\n",
        "        self.linear2=nn.Linear(H,D_out)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = torch.sigmoid(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAVCKAg1NQ_I"
      },
      "outputs": [],
      "source": [
        "input_dim = 4\n",
        "hidden_dim = 25\n",
        "output_dim = 3\n",
        "model = Net(input_dim,hidden_dim,output_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8skkViVYzSF"
      },
      "source": [
        "**Requirement:** Write script to Train and Inference\n",
        "\n",
        "* In Train script must log loss, Accuracy, Precision, Recall, F1.\n",
        "\n",
        "  *Hint:*\n",
        "\n",
        "  https://torchmetrics.readthedocs.io/en/v0.10.2/classification/precision_recall.html\n",
        "\n",
        "  https://lightning.ai/docs/torchmetrics/stable/classification/f1_score.html\n",
        "\n",
        "  https://lightning.ai/docs/torchmetrics/stable/classification/accuracy.html\n",
        "\n",
        "* View `classification_report` by `sklearn` in Inference script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwwuCgmANS-e"
      },
      "source": [
        "## Assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLjRlT-BYZa2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1dT_pImNVlv"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SrXC3m8NXUZ"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "# features, targets split\n",
        "X = iris.data\n",
        "Y = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4BGTsXCNbm3",
        "outputId": "920a4d22-74b5-4a30-cf70-162ce9776ef3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIPKsdjRNd37",
        "outputId": "42d989d6-acfc-4a7d-df9c-3956ef73ca13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAp-8sZeV3tp"
      },
      "source": [
        "**Bộ dữ liệu Iris**\n",
        "\n",
        "* Bộ dữ liệu gồm 150 mẫu, chia thành 3 lớp, mỗi lớp đại diện cho một loài hoa Iris: **Iris Setosa**, **Iris Versicolor**, và **Iris Virginica**.\n",
        "\n",
        "* Mỗi mẫu có 4 đặc trưng đo bằng cm:\n",
        "  * Chiều dài đài hoa (`Sepal Length`)\n",
        "  * Chiều rộng đài hoa (`Sepal Width`)\n",
        "  * Chiều dài cánh hoa (`Petal Length`)\n",
        "  * Chiều rộng cánh hoa (`Petal Width`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHoxqZONNZ-x"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHyZoJ13SDoV"
      },
      "outputs": [],
      "source": [
        "# Data object\n",
        "class Data(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.x = torch.from_numpy(X).float()\n",
        "        self.y = torch.from_numpy(y).long()\n",
        "        self.len = self.x.shape[0]\n",
        "    def __getitem__(self,index):\n",
        "        return self.x[index], self.y[index]\n",
        "    def __len__(self):\n",
        "        return self.len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkEcIX0pYCPE"
      },
      "outputs": [],
      "source": [
        "# DataLoader\n",
        "train_dataset = Data(x_train, y_train)\n",
        "trainloader = DataLoader(dataset=train_dataset,batch_size=64)\n",
        "val_dataset = Data(x_val, y_val)\n",
        "val_loader = DataLoader(dataset=val_dataset,batch_size=64)\n",
        "test_dataset = Data(x_train, y_train)\n",
        "test_loader = DataLoader(dataset=test_dataset,batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2sb8FAVNghF"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Aq--kLqcr_I"
      },
      "source": [
        "1. Design Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfEHYnikLbmA"
      },
      "outputs": [],
      "source": [
        "# model = nn.Net(input_dim, output_dim)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,D_in,H,D_out):\n",
        "        super(Net,self).__init__()\n",
        "        # define different layers\n",
        "        self.linear1=nn.Linear(D_in,H)\n",
        "        self.linear2=nn.Linear(H,D_out)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = torch.sigmoid(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKCmcA8rYkjJ"
      },
      "outputs": [],
      "source": [
        "input_dim = 4\n",
        "hidden_dim = 25\n",
        "output_dim = 3\n",
        "model = Net(input_dim,hidden_dim,output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgIWiyqwdub7"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Set the device\n",
        "model = model.to(device)  # Move the model to the device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcDqnuwGdXg5"
      },
      "source": [
        "2. Define loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5zItl6WdJGC"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK5Fux82axQ3"
      },
      "source": [
        "3. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-_ocEpQ7X9v",
        "outputId": "fe24eb14-2ce9-4f72-9216-1eca384659ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-a8dTxa2SlA"
      },
      "outputs": [],
      "source": [
        "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
        "\n",
        "# define metrics\n",
        "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=output_dim, average='weighted')\n",
        "precision_metric = Precision(task=\"multiclass\", num_classes=output_dim, average='weighted')\n",
        "recall_metric = Recall(task=\"multiclass\", num_classes=output_dim, average='weighted')\n",
        "f1_metric = F1Score(task=\"multiclass\", num_classes=output_dim, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGPWwyVdYmQ3",
        "outputId": "e546cce2-93a5-4c60-9afd-9c1fd25a0db4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1000] - Train: (Loss: 1.1823, Accuracy: 0.1600, Precision: 0.1191, Recall: 0.1600, F1 Score: 0.1366)\n",
            "Epoch [1/1000] - Validation: (Loss: 1.1705, Accuracy: 0.1429, Precision: 0.0779, Recall: 0.1429, F1 Score: 0.1008)\n",
            "\n",
            "Epoch [101/1000] - Train: (Loss: 0.7879, Accuracy: 0.8500, Precision: 0.8959, Recall: 0.8500, F1 Score: 0.8431)\n",
            "Epoch [101/1000] - Validation: (Loss: 0.7561, Accuracy: 0.7857, Precision: 0.8696, Recall: 0.7857, F1 Score: 0.7475)\n",
            "\n",
            "Epoch [201/1000] - Train: (Loss: 0.4806, Accuracy: 0.9600, Precision: 0.9642, Recall: 0.9600, F1 Score: 0.9599)\n",
            "Epoch [201/1000] - Validation: (Loss: 0.4330, Accuracy: 0.9762, Precision: 0.9778, Recall: 0.9762, F1 Score: 0.9761)\n",
            "\n",
            "Epoch [301/1000] - Train: (Loss: 0.3254, Accuracy: 0.9700, Precision: 0.9724, Recall: 0.9700, F1 Score: 0.9700)\n",
            "Epoch [301/1000] - Validation: (Loss: 0.2965, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000)\n",
            "\n",
            "Epoch [401/1000] - Train: (Loss: 0.2206, Accuracy: 0.9700, Precision: 0.9724, Recall: 0.9700, F1 Score: 0.9700)\n",
            "Epoch [401/1000] - Validation: (Loss: 0.2055, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000)\n",
            "\n",
            "Epoch [501/1000] - Train: (Loss: 0.1602, Accuracy: 0.9700, Precision: 0.9724, Recall: 0.9700, F1 Score: 0.9700)\n",
            "Epoch [501/1000] - Validation: (Loss: 0.1524, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000)\n",
            "\n",
            "Epoch [601/1000] - Train: (Loss: 0.1255, Accuracy: 0.9700, Precision: 0.9724, Recall: 0.9700, F1 Score: 0.9700)\n",
            "Epoch [601/1000] - Validation: (Loss: 0.1216, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000)\n",
            "\n",
            "Epoch [701/1000] - Train: (Loss: 0.1043, Accuracy: 0.9700, Precision: 0.9724, Recall: 0.9700, F1 Score: 0.9700)\n",
            "Epoch [701/1000] - Validation: (Loss: 0.1027, Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000)\n",
            "\n",
            "Epoch [801/1000] - Train: (Loss: 0.0904, Accuracy: 0.9700, Precision: 0.9724, Recall: 0.9700, F1 Score: 0.9700)\n",
            "Epoch [801/1000] - Validation: (Loss: 0.0904, Accuracy: 0.9762, Precision: 0.9780, Recall: 0.9762, F1 Score: 0.9762)\n",
            "\n",
            "Epoch [901/1000] - Train: (Loss: 0.0809, Accuracy: 0.9800, Precision: 0.9811, Recall: 0.9800, F1 Score: 0.9800)\n",
            "Epoch [901/1000] - Validation: (Loss: 0.0819, Accuracy: 0.9762, Precision: 0.9780, Recall: 0.9762, F1 Score: 0.9762)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    # Training pharse\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for x_batch, y_batch in tqdm(trainloader, disable=True):\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        optimizer.zero_grad() # zero gradients after updating\n",
        "        pred = model(x_batch)\n",
        "\n",
        "        loss_value = loss(pred, y_batch) # loss\n",
        "        loss_value.backward() # calculate gradients\n",
        "        optimizer.step() # update weights\n",
        "\n",
        "        total_loss += loss_value.item()\n",
        "        all_preds.extend(pred.cpu().detach().numpy())\n",
        "        all_labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # Calculate training accuracy and F1 score\n",
        "    all_preds = torch.as_tensor(all_preds)\n",
        "    all_labels = torch.as_tensor(all_labels)\n",
        "    train_accuracy = accuracy_metric(all_preds, all_labels)\n",
        "    train_precision = precision_metric(all_preds, all_labels)\n",
        "    train_recall = recall_metric(all_preds, all_labels)\n",
        "    train_f1 = f1_metric(all_preds, all_labels)\n",
        "    avg_train_loss = total_loss / len(trainloader)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] - '\n",
        "              f'Train: (Loss: {avg_train_loss:.4f}, '\n",
        "              f'Accuracy: {train_accuracy:.4f}, '\n",
        "              f'Precision: {train_precision:.4f}, '\n",
        "              f'Recall: {train_recall:.4f}, '\n",
        "              f'F1 Score: {train_f1:.4f})')\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_total_loss = 0\n",
        "    val_all_preds = []\n",
        "    val_all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in tqdm(val_loader, disable=True):\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            pred = model(x_batch)\n",
        "            val_loss = loss(pred, y_batch)\n",
        "\n",
        "            val_total_loss += val_loss.item()\n",
        "            val_all_preds.extend(pred.cpu().detach().numpy())\n",
        "            val_all_labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # Calculate validation accuracy and F1 score\n",
        "    all_preds = torch.as_tensor(val_all_preds)\n",
        "    all_labels = torch.as_tensor(val_all_labels)\n",
        "    val_accuracy = accuracy_metric(all_preds, all_labels)\n",
        "    val_precision = precision_metric(all_preds, all_labels)\n",
        "    val_recall = recall_metric(all_preds, all_labels)\n",
        "    val_f1 = f1_metric(all_preds, all_labels)\n",
        "    avg_val_loss = val_total_loss / len(val_loader)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] - '\n",
        "              f'Validation: (Loss: {avg_val_loss:.4f}, '\n",
        "              f'Accuracy: {val_accuracy:.4f}, '\n",
        "              f'Precision: {val_precision:.4f}, '\n",
        "              f'Recall: {val_recall:.4f}, '\n",
        "              f'F1 Score: {val_f1:.4f})\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCPCs-mg06Tf"
      },
      "source": [
        "4. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sob0qff51rAx",
        "outputId": "65231dfd-a11a-4a35-acc2-75428766cc7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        31\n",
            "  versicolor       1.00      0.94      0.97        35\n",
            "   virginica       0.94      1.00      0.97        34\n",
            "\n",
            "    accuracy                           0.98       100\n",
            "   macro avg       0.98      0.98      0.98       100\n",
            "weighted avg       0.98      0.98      0.98       100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have your test dataloader and model set up\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "# Evaluate the model on the test DataLoader\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation to save storage\n",
        "    for x, y in test_loader:  # Replace with your test dataloader\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        outputs = model(x)  # Your model's forward pass\n",
        "        _, preds = torch.max(outputs, 1)  # Get the predicted class\n",
        "\n",
        "        all_labels.extend(y.cpu().numpy())  # Collect true labels\n",
        "        all_preds.extend(preds.cpu().numpy())  # Collect predictions\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "\n",
        "# Generate and print the classification report\n",
        "report = classification_report(all_labels, all_preds, target_names=iris.target_names)  # Adjust class names as needed\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
